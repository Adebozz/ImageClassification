{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1 : Importing Essetial Libraries","metadata":{"papermill":{"duration":0.010801,"end_time":"2023-04-08T14:54:29.68854","exception":false,"start_time":"2023-04-08T14:54:29.677739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":9.222684,"end_time":"2023-04-08T14:54:38.921024","exception":false,"start_time":"2023-04-08T14:54:29.69834","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:44:52.379215Z","iopub.execute_input":"2023-04-13T15:44:52.37964Z","iopub.status.idle":"2023-04-13T15:45:09.259877Z","shell.execute_reply.started":"2023-04-13T15:44:52.3796Z","shell.execute_reply":"2023-04-13T15:45:09.258665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2 : Importing Data and Creating a Dataframe","metadata":{"papermill":{"duration":0.00893,"end_time":"2023-04-08T14:54:38.939672","exception":false,"start_time":"2023-04-08T14:54:38.930742","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ntrain_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'\ntest_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test'\n\n# Create dataframes\ntrain_df = pd.DataFrame(columns=['image_path', 'label'])\ntest_df = pd.DataFrame(columns=['image_path', 'label'])\n\n# Add images paths and labels to dataframes\nfor label, directory in enumerate(os.listdir(train_dir)):\n    for filename in os.listdir(os.path.join(train_dir, directory)):\n        image_path = os.path.join(train_dir, directory, filename)\n        train_df = train_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n\nfor label, directory in enumerate(os.listdir(test_dir)):\n    for filename in os.listdir(os.path.join(test_dir, directory)):\n        image_path = os.path.join(test_dir, directory, filename)\n        test_df = test_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n        \n# Combine train_df and test_df into one dataframe\ndf = pd.concat([train_df, test_df], ignore_index=True)\ndel test_df,train_df\ndf","metadata":{"papermill":{"duration":4.466736,"end_time":"2023-04-08T14:54:43.416586","exception":false,"start_time":"2023-04-08T14:54:38.94985","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:09.262017Z","iopub.execute_input":"2023-04-13T15:45:09.262783Z","iopub.status.idle":"2023-04-13T15:45:13.911914Z","shell.execute_reply.started":"2023-04-13T15:45:09.262742Z","shell.execute_reply":"2023-04-13T15:45:13.910799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get list of directories in train_dir\nlabels = os.listdir(train_dir)\n\n# Create label_map dictionary\nlabel_map = {i: label for i, label in enumerate(labels)}\nnum_classes=len(label_map)\nlabel_map","metadata":{"papermill":{"duration":0.020698,"end_time":"2023-04-08T14:54:43.522854","exception":false,"start_time":"2023-04-08T14:54:43.502156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:13.91359Z","iopub.execute_input":"2023-04-13T15:45:13.913963Z","iopub.status.idle":"2023-04-13T15:45:13.924098Z","shell.execute_reply.started":"2023-04-13T15:45:13.913926Z","shell.execute_reply":"2023-04-13T15:45:13.922938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3 : EDA","metadata":{"papermill":{"duration":0.009509,"end_time":"2023-04-08T14:54:43.570674","exception":false,"start_time":"2023-04-08T14:54:43.561165","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Plot pie chart of train_df\ndf['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\nplt.axis('equal')\nplt.title('Distribution of Labels in DataFrame')\nplt.legend(df['label'].unique())\nplt.show()","metadata":{"papermill":{"duration":0.372667,"end_time":"2023-04-08T14:54:43.953259","exception":false,"start_time":"2023-04-08T14:54:43.580592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:13.927576Z","iopub.execute_input":"2023-04-13T15:45:13.928088Z","iopub.status.idle":"2023-04-13T15:45:14.320116Z","shell.execute_reply.started":"2023-04-13T15:45:13.928049Z","shell.execute_reply":"2023-04-13T15:45:14.319099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:45:14.322018Z","iopub.execute_input":"2023-04-13T15:45:14.322678Z","iopub.status.idle":"2023-04-13T15:45:14.335209Z","shell.execute_reply.started":"2023-04-13T15:45:14.322636Z","shell.execute_reply":"2023-04-13T15:45:14.334174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4 : Loading and resizing of images","metadata":{"papermill":{"duration":0.010587,"end_time":"2023-04-08T14:54:43.974718","exception":false,"start_time":"2023-04-08T14:54:43.964131","status":"completed"},"tags":[]}},{"cell_type":"code","source":"max_images_per_class = 2500\n\n# Group by label column and take first max_images_per_class rows for each group\ndf = df.groupby(\"label\").apply(lambda x: x.head(max_images_per_class)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:45:14.336584Z","iopub.execute_input":"2023-04-13T15:45:14.337267Z","iopub.status.idle":"2023-04-13T15:45:14.355528Z","shell.execute_reply.started":"2023-04-13T15:45:14.33723Z","shell.execute_reply":"2023-04-13T15:45:14.354326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Allow gpu usage\ngpus = tf.config.experimental.list_physical_devices('GPU')\nprint(gpus)\ntry:\n    tf.config.experimental.set_memory_growth = True\nexcept Exception as ex:\n    print(e)","metadata":{"papermill":{"duration":0.316802,"end_time":"2023-04-08T14:54:44.301568","exception":false,"start_time":"2023-04-08T14:54:43.984766","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:14.357204Z","iopub.execute_input":"2023-04-13T15:45:14.35772Z","iopub.status.idle":"2023-04-13T15:45:14.842235Z","shell.execute_reply.started":"2023-04-13T15:45:14.357677Z","shell.execute_reply":"2023-04-13T15:45:14.839887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\n# Get the number of CPU cores available\nmax_workers = multiprocessing.cpu_count()\nmax_workers","metadata":{"papermill":{"duration":0.020755,"end_time":"2023-04-08T14:54:44.332822","exception":false,"start_time":"2023-04-08T14:54:44.312067","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:14.844273Z","iopub.execute_input":"2023-04-13T15:45:14.845155Z","iopub.status.idle":"2023-04-13T15:45:14.854545Z","shell.execute_reply.started":"2023-04-13T15:45:14.8451Z","shell.execute_reply":"2023-04-13T15:45:14.853287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import concurrent.futures\n\n# Define a function to resize image arrays\ndef resize_image_array(image_path):\n    return np.asarray(Image.open(image_path).resize((100,75)))\n\n# Use concurrent.futures to parallelize the resizing process\nwith concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n    # Use executor.map to apply the function to each image path in the DataFrame\n    image_arrays = list(executor.map(resize_image_array, df['image_path'].tolist()))\n\n# Add the resized image arrays to the DataFrame\ndf['image'] = image_arrays\ndel image_arrays","metadata":{"papermill":{"duration":51.02496,"end_time":"2023-04-08T14:55:35.368114","exception":false,"start_time":"2023-04-08T14:54:44.343154","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:45:14.856462Z","iopub.execute_input":"2023-04-13T15:45:14.857264Z","iopub.status.idle":"2023-04-13T15:46:12.024184Z","shell.execute_reply.started":"2023-04-13T15:45:14.857224Z","shell.execute_reply":"2023-04-13T15:46:12.023094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot pie chart of train_df\ndf['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\nplt.axis('equal')\nplt.title('Distribution of Labels in DataFrame')\nplt.legend(df['label'].unique())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:46:12.029346Z","iopub.execute_input":"2023-04-13T15:46:12.029638Z","iopub.status.idle":"2023-04-13T15:46:12.343458Z","shell.execute_reply.started":"2023-04-13T15:46:12.029609Z","shell.execute_reply":"2023-04-13T15:46:12.342468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":9.082972,"end_time":"2023-04-08T14:55:44.462695","exception":false,"start_time":"2023-04-08T14:55:35.379723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:46:12.345055Z","iopub.execute_input":"2023-04-13T15:46:12.345695Z","iopub.status.idle":"2023-04-13T15:46:21.637911Z","shell.execute_reply.started":"2023-04-13T15:46:12.345652Z","shell.execute_reply":"2023-04-13T15:46:21.636825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class before Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:46:21.639265Z","iopub.execute_input":"2023-04-13T15:46:21.639977Z","iopub.status.idle":"2023-04-13T15:46:21.6488Z","shell.execute_reply.started":"2023-04-13T15:46:21.639944Z","shell.execute_reply":"2023-04-13T15:46:21.647562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = 7\nfig, m_axs = plt.subplots(num_classes, n_samples, figsize=(4*n_samples, 3*7))\nfor n_axs, (class_idx, class_rows) in zip(m_axs, df.sort_values(['label']).groupby('label')):\n    class_name = label_map[class_idx] # get the class name using label_map\n    n_axs[0].set_title(class_name)\n    for c_ax, (_, c_row) in zip(n_axs, class_rows.sample(n_samples, random_state=5).iterrows()):\n        c_ax.imshow(c_row['image'])\n        c_ax.axis('off')","metadata":{"papermill":{"duration":3.775445,"end_time":"2023-04-08T14:55:48.249354","exception":false,"start_time":"2023-04-08T14:55:44.473909","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:46:21.650331Z","iopub.execute_input":"2023-04-13T15:46:21.650956Z","iopub.status.idle":"2023-04-13T15:46:25.37601Z","shell.execute_reply.started":"2023-04-13T15:46:21.650918Z","shell.execute_reply":"2023-04-13T15:46:25.373903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['image'].map(lambda x: x.shape).value_counts()","metadata":{"papermill":{"duration":0.061411,"end_time":"2023-04-08T14:55:48.357706","exception":false,"start_time":"2023-04-08T14:55:48.296295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:46:25.377509Z","iopub.execute_input":"2023-04-13T15:46:25.378035Z","iopub.status.idle":"2023-04-13T15:46:25.390372Z","shell.execute_reply.started":"2023-04-13T15:46:25.377976Z","shell.execute_reply":"2023-04-13T15:46:25.389426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5 : Data Augmentation","metadata":{"papermill":{"duration":0.047425,"end_time":"2023-04-08T14:56:00.20678","exception":false,"start_time":"2023-04-08T14:56:00.159355","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# Create an ImageDataGenerator object with the desired transformations\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:46:25.392127Z","iopub.execute_input":"2023-04-13T15:46:25.392719Z","iopub.status.idle":"2023-04-13T15:46:25.398615Z","shell.execute_reply.started":"2023-04-13T15:46:25.392684Z","shell.execute_reply":"2023-04-13T15:46:25.397658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an empty dataframe to store the augmented images\naugmented_df = pd.DataFrame(columns=['image_path', 'label', 'image'])\n\n# Loop through each class label and generate additional images if needed\nfor class_label in df['label'].unique():\n    # Get the image arrays for the current class\n    image_arrays = df.loc[df['label'] == class_label, 'image'].values\n    \n    # Calculate the number of additional images needed for the current class\n    num_images_needed = max_images_per_class - len(image_arrays)\n    \n    # Generate augmented images for the current class\n    if num_images_needed > 0:\n        # Select a random subset of the original images\n        selected_images = np.random.choice(image_arrays, size=num_images_needed)\n        \n        # Apply transformations to the selected images and add them to the augmented dataframe\n        for image_array in selected_images:\n            # Reshape the image array to a 4D tensor with a batch size of 1\n            image_tensor = np.expand_dims(image_array, axis=0)\n            \n            # Generate the augmented images\n            augmented_images = datagen.flow(image_tensor, batch_size=1)\n            \n            # Extract the augmented image arrays and add them to the augmented dataframe\n            for i in range(augmented_images.n):\n                augmented_image_array = augmented_images.next()[0].astype('uint8')\n                augmented_df = augmented_df.append({'image_path': None, 'label': class_label, 'image': augmented_image_array}, ignore_index=True)\n    \n    # Add the original images for the current class to the augmented dataframe\n    original_images_df = df.loc[df['label'] == class_label, ['image_path', 'label', 'image']]\n    augmented_df = augmented_df.append(original_images_df, ignore_index=True)\n\n# Group the augmented dataframe by the 'label' column and filter out extra images\ndf = augmented_df.groupby('label').head(max_images_per_class)\n\ndel augmented_df\n\n# Use the augmented dataframe for further processing\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:46:25.400089Z","iopub.execute_input":"2023-04-13T15:46:25.400827Z","iopub.status.idle":"2023-04-13T15:48:06.931239Z","shell.execute_reply.started":"2023-04-13T15:46:25.400775Z","shell.execute_reply":"2023-04-13T15:48:06.930168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class after Data Augmentation","metadata":{"papermill":{"duration":0.046393,"end_time":"2023-04-08T14:56:00.879027","exception":false,"start_time":"2023-04-08T14:56:00.832634","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:06.932728Z","iopub.execute_input":"2023-04-13T15:48:06.933107Z","iopub.status.idle":"2023-04-13T15:48:06.943183Z","shell.execute_reply.started":"2023-04-13T15:48:06.933067Z","shell.execute_reply":"2023-04-13T15:48:06.941948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6 : Train and Test split","metadata":{"papermill":{"duration":0.046342,"end_time":"2023-04-08T14:55:48.448187","exception":false,"start_time":"2023-04-08T14:55:48.401845","status":"completed"},"tags":[]}},{"cell_type":"code","source":"features = df.drop(columns=['label','image_path'],axis=1)\ntarget = df['label']","metadata":{"papermill":{"duration":0.056845,"end_time":"2023-04-08T14:55:48.551537","exception":false,"start_time":"2023-04-08T14:55:48.494692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:06.945023Z","iopub.execute_input":"2023-04-13T15:48:06.945887Z","iopub.status.idle":"2023-04-13T15:48:06.959157Z","shell.execute_reply.started":"2023-04-13T15:48:06.945848Z","shell.execute_reply":"2023-04-13T15:48:06.958242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"papermill":{"duration":9.197518,"end_time":"2023-04-08T14:55:57.793734","exception":false,"start_time":"2023-04-08T14:55:48.596216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:06.960508Z","iopub.execute_input":"2023-04-13T15:48:06.96269Z","iopub.status.idle":"2023-04-13T15:48:16.847797Z","shell.execute_reply.started":"2023-04-13T15:48:06.962648Z","shell.execute_reply":"2023-04-13T15:48:16.846776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"papermill":{"duration":0.057596,"end_time":"2023-04-08T14:55:57.896986","exception":false,"start_time":"2023-04-08T14:55:57.83939","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:16.849093Z","iopub.execute_input":"2023-04-13T15:48:16.84987Z","iopub.status.idle":"2023-04-13T15:48:16.857906Z","shell.execute_reply.started":"2023-04-13T15:48:16.849836Z","shell.execute_reply":"2023-04-13T15:48:16.856532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(target.shape,features.shape)","metadata":{"papermill":{"duration":0.058722,"end_time":"2023-04-08T14:55:58.000264","exception":false,"start_time":"2023-04-08T14:55:57.941542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:16.859834Z","iopub.execute_input":"2023-04-13T15:48:16.860615Z","iopub.status.idle":"2023-04-13T15:48:16.867204Z","shell.execute_reply.started":"2023-04-13T15:48:16.860577Z","shell.execute_reply":"2023-04-13T15:48:16.865825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20,shuffle=True)","metadata":{"papermill":{"duration":0.073134,"end_time":"2023-04-08T14:55:58.119128","exception":false,"start_time":"2023-04-08T14:55:58.045994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:16.869337Z","iopub.execute_input":"2023-04-13T15:48:16.870274Z","iopub.status.idle":"2023-04-13T15:48:16.88117Z","shell.execute_reply.started":"2023-04-13T15:48:16.870236Z","shell.execute_reply":"2023-04-13T15:48:16.880056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7 : Normalization of Data","metadata":{"papermill":{"duration":0.07358,"end_time":"2023-04-08T14:55:58.265239","exception":false,"start_time":"2023-04-08T14:55:58.191659","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x_train = np.asarray(x_train['image'].tolist())\nx_test = np.asarray(x_test['image'].tolist())\n\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean)/x_train_std\nx_test = (x_test - x_test_mean)/x_test_std","metadata":{"papermill":{"duration":0.668418,"end_time":"2023-04-08T14:55:59.006266","exception":false,"start_time":"2023-04-08T14:55:58.337848","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:16.882632Z","iopub.execute_input":"2023-04-13T15:48:16.883142Z","iopub.status.idle":"2023-04-13T15:48:21.46336Z","shell.execute_reply.started":"2023-04-13T15:48:16.883107Z","shell.execute_reply":"2023-04-13T15:48:21.462151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8 : Label Encoding","metadata":{"papermill":{"duration":0.078137,"end_time":"2023-04-08T14:55:59.163475","exception":false,"start_time":"2023-04-08T14:55:59.085338","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Perform one-hot encoding on the labels\ny_train = to_categorical(y_train,num_classes = num_classes)\ny_test = to_categorical(y_test,num_classes = num_classes)","metadata":{"papermill":{"duration":0.08297,"end_time":"2023-04-08T14:55:59.322888","exception":false,"start_time":"2023-04-08T14:55:59.239918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:21.46531Z","iopub.execute_input":"2023-04-13T15:48:21.465728Z","iopub.status.idle":"2023-04-13T15:48:21.474703Z","shell.execute_reply.started":"2023-04-13T15:48:21.465681Z","shell.execute_reply":"2023-04-13T15:48:21.473486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9 : Splitting the data into training and Validation Split","metadata":{"papermill":{"duration":0.069844,"end_time":"2023-04-08T14:55:59.461622","exception":false,"start_time":"2023-04-08T14:55:59.391778","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2,shuffle=True)","metadata":{"papermill":{"duration":0.172387,"end_time":"2023-04-08T14:55:59.705234","exception":false,"start_time":"2023-04-08T14:55:59.532847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:21.476498Z","iopub.execute_input":"2023-04-13T15:48:21.476975Z","iopub.status.idle":"2023-04-13T15:48:22.434705Z","shell.execute_reply.started":"2023-04-13T15:48:21.47693Z","shell.execute_reply":"2023-04-13T15:48:22.433623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\nx_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\nx_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\nx_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))","metadata":{"papermill":{"duration":0.058202,"end_time":"2023-04-08T14:55:59.809335","exception":false,"start_time":"2023-04-08T14:55:59.751133","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:22.436464Z","iopub.execute_input":"2023-04-13T15:48:22.43686Z","iopub.status.idle":"2023-04-13T15:48:22.442947Z","shell.execute_reply.started":"2023-04-13T15:48:22.436815Z","shell.execute_reply":"2023-04-13T15:48:22.441871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype(int)\ny_validate = y_validate.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:22.444855Z","iopub.execute_input":"2023-04-13T15:48:22.445565Z","iopub.status.idle":"2023-04-13T15:48:22.453628Z","shell.execute_reply.started":"2023-04-13T15:48:22.445524Z","shell.execute_reply":"2023-04-13T15:48:22.452536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class","metadata":{"papermill":{"duration":0.045372,"end_time":"2023-04-08T14:55:59.899776","exception":false,"start_time":"2023-04-08T14:55:59.854404","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Calculate the number of images in each class for train, validation, and test datasets\ntrain_counts = np.sum(y_train, axis=0)\nval_counts = np.sum(y_validate, axis=0)\ntest_counts = np.sum(y_test, axis=0)\n\n# Print the number of images in each class for train, validation, and test datasets\nprint(\"Dataset Summary\")\nprint(\"-\" * 90)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Train':<10} {'Validation':<12} {'Test':<10} {'Total':<10}\")\nprint(\"-\" * 90)\nfor class_label, class_name in label_map.items():\n    train_num = int(train_counts[class_label])\n    val_num = int(val_counts[class_label])\n    test_num = int(test_counts[class_label])\n    total_num = train_num + val_num + test_num\n    print(f\"{class_label:<15} {class_name:<30} {train_num:<10} {val_num:<12} {test_num:<10} {total_num:<10}\")\nprint(\"-\" * 90)\nprint(f\"{'Total':<46} {len(y_train):<10} {len(y_validate):<12} {len(y_test):<10} {len(y_train) + len(y_validate) + len(y_test):<10}\")","metadata":{"papermill":{"duration":0.059918,"end_time":"2023-04-08T14:56:00.005082","exception":false,"start_time":"2023-04-08T14:55:59.945164","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:22.460412Z","iopub.execute_input":"2023-04-13T15:48:22.46067Z","iopub.status.idle":"2023-04-13T15:48:22.470652Z","shell.execute_reply.started":"2023-04-13T15:48:22.460645Z","shell.execute_reply":"2023-04-13T15:48:22.469241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('label').size()","metadata":{"papermill":{"duration":0.061936,"end_time":"2023-04-08T14:56:00.11278","exception":false,"start_time":"2023-04-08T14:56:00.050844","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:22.472518Z","iopub.execute_input":"2023-04-13T15:48:22.47323Z","iopub.status.idle":"2023-04-13T15:48:22.489133Z","shell.execute_reply.started":"2023-04-13T15:48:22.473192Z","shell.execute_reply":"2023-04-13T15:48:22.488119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = df['image'][0].shape","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:22.490774Z","iopub.execute_input":"2023-04-13T15:48:22.491587Z","iopub.status.idle":"2023-04-13T15:48:22.496496Z","shell.execute_reply.started":"2023-04-13T15:48:22.491549Z","shell.execute_reply":"2023-04-13T15:48:22.495333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10 : Model Architecture","metadata":{"papermill":{"duration":0.047796,"end_time":"2023-04-08T14:56:04.40223","exception":false,"start_time":"2023-04-08T14:56:04.354434","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n\n# DenseNet121\nmodel = Sequential()\nmodel.add(DenseNet121(include_top=False, weights='imagenet', input_shape=input_shape))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:22.498087Z","iopub.execute_input":"2023-04-13T15:48:22.498536Z","iopub.status.idle":"2023-04-13T15:48:31.3456Z","shell.execute_reply.started":"2023-04-13T15:48:22.498495Z","shell.execute_reply":"2023-04-13T15:48:31.344531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11 : Setting Optimizer","metadata":{"papermill":{"duration":0.047812,"end_time":"2023-04-08T14:56:08.36329","exception":false,"start_time":"2023-04-08T14:56:08.315478","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# compile model\nfrom keras.optimizers import SGD\nopt = SGD(learning_rate=0.001, momentum=0.9)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                            patience=3,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.00001)","metadata":{"papermill":{"duration":0.072304,"end_time":"2023-04-08T14:56:08.483893","exception":false,"start_time":"2023-04-08T14:56:08.411589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:31.347365Z","iopub.execute_input":"2023-04-13T15:48:31.34777Z","iopub.status.idle":"2023-04-13T15:48:31.37555Z","shell.execute_reply.started":"2023-04-13T15:48:31.347726Z","shell.execute_reply":"2023-04-13T15:48:31.374613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12: Fitting of model","metadata":{"papermill":{"duration":0.047969,"end_time":"2023-04-08T14:56:08.580204","exception":false,"start_time":"2023-04-08T14:56:08.532235","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Fit the model\nepochs = 100\nbatch_size=32\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=epochs,\n                    batch_size=batch_size,\n                    validation_data=(x_validate,y_validate),\n                    callbacks=learning_rate_reduction)","metadata":{"_kg_hide-output":true,"papermill":{"duration":445.934022,"end_time":"2023-04-08T15:03:34.562326","exception":false,"start_time":"2023-04-08T14:56:08.628304","status":"completed"},"tags":[],"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-04-13T15:48:31.376851Z","iopub.execute_input":"2023-04-13T15:48:31.377339Z","iopub.status.idle":"2023-04-13T16:51:07.074903Z","shell.execute_reply.started":"2023-04-13T15:48:31.3773Z","shell.execute_reply":"2023-04-13T16:51:07.073706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 13 : Model Evaluation","metadata":{"papermill":{"duration":0.307748,"end_time":"2023-04-08T15:03:35.236846","exception":false,"start_time":"2023-04-08T15:03:34.929098","status":"completed"},"tags":[],"_kg_hide-input":false}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(x_train, y_train, verbose=1)\nprint(\"Train: accuracy = %f  ;  loss = %f\" % (accuracy, loss))","metadata":{"papermill":{"duration":1.130804,"end_time":"2023-04-08T15:03:36.677668","exception":false,"start_time":"2023-04-08T15:03:35.546864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T16:51:07.076882Z","iopub.execute_input":"2023-04-13T16:51:07.0778Z","iopub.status.idle":"2023-04-13T16:51:22.115542Z","shell.execute_reply.started":"2023-04-13T16:51:07.077755Z","shell.execute_reply":"2023-04-13T16:51:22.113292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\nprint(\"Testing: accuracy = %f  ;  loss = %f\" % (accuracy, loss))","metadata":{"papermill":{"duration":0.835439,"end_time":"2023-04-08T15:03:37.824937","exception":false,"start_time":"2023-04-08T15:03:36.989498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T16:51:22.11731Z","iopub.execute_input":"2023-04-13T16:51:22.118752Z","iopub.status.idle":"2023-04-13T16:51:30.264552Z","shell.execute_reply.started":"2023-04-13T16:51:22.118695Z","shell.execute_reply":"2023-04-13T16:51:30.26328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Get the predicted probabilities for the test set\ny_pred_prob = model.predict(x_test)\n\n# Find the class with the highest probability for each sample\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Calculate the confusion matrix\ncm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n\n# Plot the confusion matrix using Seaborn\nsns.heatmap(cm, annot=True, cmap='Blues')","metadata":{"papermill":{"duration":1.551737,"end_time":"2023-04-08T15:03:39.710856","exception":false,"start_time":"2023-04-08T15:03:38.159119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T16:51:30.266411Z","iopub.execute_input":"2023-04-13T16:51:30.266816Z","iopub.status.idle":"2023-04-13T16:51:38.248009Z","shell.execute_reply.started":"2023-04-13T16:51:30.266762Z","shell.execute_reply":"2023-04-13T16:51:38.246871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\nprecision = precision_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nrecall = recall_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nf1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nkappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1:.4f}\")\nprint(f\"Kappa score: {kappa:.4f}\")","metadata":{"papermill":{"duration":0.34869,"end_time":"2023-04-08T15:03:40.378395","exception":false,"start_time":"2023-04-08T15:03:40.029705","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T16:51:38.249409Z","iopub.execute_input":"2023-04-13T16:51:38.250108Z","iopub.status.idle":"2023-04-13T16:51:38.271321Z","shell.execute_reply.started":"2023-04-13T16:51:38.250065Z","shell.execute_reply":"2023-04-13T16:51:38.270203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Get training and testing accuracy and loss histories\ntraining_accuracy = history.history['accuracy']\ntesting_accuracy = history.history['val_accuracy']\ntraining_loss = history.history['loss']\ntesting_loss = history.history['val_loss']\n\n# Plot training and testing accuracy curves\nplt.plot(training_accuracy)\nplt.plot(testing_accuracy)\nplt.title('Training vs Testing Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Testing'], loc='lower right')\nplt.show()\n\n# Plot training and testing loss curves\nplt.plot(training_loss)\nplt.plot(testing_loss)\nplt.title('Training vs Testing Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Testing'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:51:38.272825Z","iopub.execute_input":"2023-04-13T16:51:38.27335Z","iopub.status.idle":"2023-04-13T16:51:38.725948Z","shell.execute_reply.started":"2023-04-13T16:51:38.273312Z","shell.execute_reply":"2023-04-13T16:51:38.724825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 14 : Saving the model","metadata":{"papermill":{"duration":0.312943,"end_time":"2023-04-08T15:03:42.162912","exception":false,"start_time":"2023-04-08T15:03:41.849969","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model.save(\"skinDiseaseDetectionUsningCNN.h5\")","metadata":{"papermill":{"duration":0.371481,"end_time":"2023-04-08T15:03:42.849757","exception":false,"start_time":"2023-04-08T15:03:42.478276","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T16:51:38.727606Z","iopub.execute_input":"2023-04-13T16:51:38.729001Z","iopub.status.idle":"2023-04-13T16:51:38.733428Z","shell.execute_reply.started":"2023-04-13T16:51:38.728957Z","shell.execute_reply":"2023-04-13T16:51:38.732291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.341888,"end_time":"2023-04-08T15:03:43.50365","exception":false,"start_time":"2023-04-08T15:03:43.161762","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}